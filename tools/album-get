#!/bin/bash
DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
. $DIR/lib.sh

declare -i TTL=0
if [[ $# = 0 ]]; then
  export COUNTFILE=$(mktemp)

  for i in $(ls); do
    if [[ -d $i ]]; then
      ${BASH_SOURCE[0]} $i
      check_for_stop
      TTL+=$(< $COUNTFILE )
    fi
  done

  echo "(Total) Added $TTL releases $(date)"
  exit
fi

base_path=$PWD
while [[ $# -gt 0 ]]; do
  check_for_stop
  arg=${1%%.}

  if [[ $arg =~ \. ]]; then
    if [[ -n "$2" ]]; then 
      base="$2" 
      domain=$arg
      base_url=$arg
      shift
    else 
      base=$( echo $arg | sed -n 's/\..*$//p' )
      base_url=$arg
    fi
    extra=
  else
    base=$arg
    base_url=$base.bandcamp.com
    extra=music
  fi
  shift

  [[ -e $base ]] || mkdir $base

  base_name=$base
  if [[ -e $base/domain ]]; then
    base_url=$(< $base/domain )
    base_name=$base_url
  elif [[ -n "$domain" ]]; then
    echo $base_url > $base/domain
  fi
  ttl=$(ls $base | grep -v domain | wc -l)

  starting_point="$PWD/$base"

  if [[ -f "$starting_point/no" ]]; then
    echo "! $base_name purged"
    exit 0
  else
    echo "♫ $base_name ♫ ($ttl)"
  fi

  url=https://$base_url/$extra
  for full in $(curl -s $url | grep -Po '(?<=")[\w:\/\.]+(?<=(album|track)\/)[^?'"'"'"]*' | sort | uniq ); do
    check_for_stop
    # sometimes we get x-dom references, sometimes it's relevant. We resolve that below.
    place="$starting_point/"$(basename "$full")
    isnew=
    manual_pull=

    if [[ ! -e "$place" ]]; then
      isnew=true
      mkdir "$place"
    fi

    # if we haven't any files then we just try to download from it again... 
    exitcode=0
    [[ -e $place/exit-code ]] && exitcode=$(< $place/exit-code )

    # Make sure the path is full
    count=$( /bin/ls "$place" 2> /dev/null | /bin/grep -Ev '\/(page.html|exit-code|album-art.jpg|domain)$' | /usr/bin/wc -l )

    # [[ "$count" = "1" ]] && [[ ! -e "$place"/no ]] && ls "$place/"
    echo "- $place ($count)"

    if [[ "$count" = "0" || $exitcode != "0" ]]; then
      [[ -e "$place/exit-code" ]] && rm "$place/exit-code"
      echo "--- $place"

      # here's where we look for the full url
      if [[ $full =~ : ]]; then
        url=$full
      else
        url=https://$base_url$full
      fi
      echo $url > "$place"/domain
      echo "  ⇩ $url"

      [[ -e "$place"/no-files ]] && continue

      # this means we've been here before. We can use the -g 
      # option to see if nothing ought to be downloaded in which
      # case we mark it as skippable
      if [[ -z "$isnew" ]]; then
        # this is a manual scrape for youtube-dl which can get confused.
        manual_pull=0

        # we put in some kind of backoff strategy
        sleep 3
        track_count=$( youtube-dl -if mp3-128 -g -- "$url" | wc -l )
        if [[ "$track_count" = "0" ]]; then
          echo "  ( no files )"
          touch "$place"/no-files
          continue
        fi
      fi

      # sometimes people are posting wav files ... really, that's crazy
      if [[ -n "$FULLALBUM" ]]; then 
        if [[ -n "$manual_pull" ]]; then
          manual_pull "$url" "$place"

        else
          get_mp3s "$url" "$place"
        fi
      else
        get_urls "$url" "$place"
      fi
      get_page "$place"

      echo "$(date +%Y%m%d) $place $url" >> "$base_path/.dl_history"
      (( TTL ++ ))
    fi
  done
done

[[ -n "$COUNTFILE" ]] && echo $TTL > $COUNTFILE
[[ $TTL -gt 0 ]] && echo "Added $TTL"
